# AOA (Agent-of-Agents) for StructuredReasoning

The Agent-of-Agents (AOA) framework, implemented as **FirmAgent** in our paper, enables adaptive task routing by learning from agent execution traces and synthesizing intelligent routing policies. This document details the core workflow for generating and evaluating AOA routing rules.

---

## Step 1: Trace-based Experience Extraction

This step analyzes individual reasoning traces from base agents to extract actionable insights (bullets) and synthesizes them into a unified routing policy.

**Script**: `Agents/aoa/experience_from_traces.py`

```bash
python3 -m Agents.aoa.experience_from_traces \
  --results_root results/StructuredReasoning_run \
  --mode online \
  --task_config StructuredReasoning/data/task_config.json \
  --classifications_jsonl results/StructuredReasoning_run/llm_reclassify_mode/capability_difficulty_score_v1_merged_finer_try50/test/classifications.jsonl \
  --k_per_task_agent 50 \
  --seed 42 \
  --workers 8 \
  --meta_max_bullets 600 \
  --api_provider usd_guiji \
  --model USD-guiji/deepseek-v3 \
  --out results/StructuredReasoning_run/aoa_mode/experience/experience.latest.json
```

**Key Arguments**:
- `--results_root`: Root directory containing base agent online results.
- `--classifications_jsonl`: Path to the sample-level capability and difficulty classifications.
- `--k_per_task_agent`: Number of samples to analyze per agent/task combination for experience extraction.
- `--meta_max_bullets`: Maximum number of bullets to provide to the meta-synthesizer.
- `--out`: Path to save the synthesized `experience.latest.json`, which contains the `routing_policy`.

---

## Step 2: Rule-based Routing Evaluation

This step evaluates the synthesized routing policy by applying the deterministic rules to all test samples. It assigns each sample to a base agent and reuses existing execution results to compute the overall performance of the AOA framework.

**Script**: `Agents/aoa/as_agent_capability_eval.py`

```bash
python3 -m Agents.aoa.as_agent_capability_eval \
  --experience_json results/StructuredReasoning_run/aoa_mode/experience/experience.latest.json \
  --cap_eval_root results/StructuredReasoning_run/capability_eval_mode \
  --mode online \
  --out_cap_eval_root results/StructuredReasoning_run/capability_eval_mode
```

**Output**:
- `.../capability_eval_mode/aoa/online/<aligned_ts>/as_agent_capability_eval/per_sample.jsonl`: Sample-level routing decisions and outcomes.
- `.../capability_eval_mode/aoa/online/<aligned_ts>/as_agent_capability_eval/summary.json`: Aggregated accuracy metrics for the AOA agent.

After running this evaluation, the `aoa` results will be available for comparison in the final performance tables generated by `utils.capability_eval`.
